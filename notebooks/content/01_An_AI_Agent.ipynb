{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Building an AI Agent\n",
        "\n",
        "In this workshop, we will do the following:\n",
        "- Define Agentic AI\n",
        "- Build an AI agent using tools\n",
        "- Understanding why agents are distributed systems\n",
        "- Identify distributed system challenges for AI agents\n",
        "- Recognize when agents become workflows"
      ],
      "metadata": {
        "id": "X9zkChjcPptZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hands-on Moments\n",
        "\n",
        "This is a hands-on workshop!\n",
        "\n",
        "All of the instructors slides and code samples are are executable in the workshop notebooks.\n",
        "We encourage you to follow along and play with the samples!\n",
        "\n",
        "At the end of every chapter (notebook) will be a hands-on lab.\n",
        "This a self-guided experience where the instructor gives a prompt (not an llm haha) with a notebook and some starter code and the attendees solve the puzzle.\n",
        "\n",
        "We are going to create a Research Agent that makes a call to the OpenAI API, conducts research on a topic of your choice, and generates a PDF report from that research. Let's go ahead and first set up your notebook."
      ],
      "metadata": {
        "id": "RyJ9MCfUkdGm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbEBnIn7H1Yg",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daad8fbe-870a-4550-e8be-3005600c69e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m349.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.4/278.4 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# We'll first install the necessary packages for this workshop.\n",
        "\n",
        "%pip install --quiet litellm reportlab python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mermaid renderer, run at the beginning to setup rendering of diagrams\n",
        "import base64\n",
        "from IPython.display import Image, display\n",
        "\n",
        "def render_mermaid(graph_definition):\n",
        "    \"\"\"\n",
        "    Renders a Mermaid diagram in Google Colab using mermaid.ink.\n",
        "\n",
        "    Args:\n",
        "        graph_definition (str): The Mermaid diagram code (e.g., \"graph LR; A-->B;\").\n",
        "    \"\"\"\n",
        "    graph_bytes = graph_definition.encode(\"ascii\")\n",
        "    base64_bytes = base64.b64encode(graph_bytes)\n",
        "    base64_string = base64_bytes.decode(\"ascii\")\n",
        "    display(Image(url=\"https://mermaid.ink/img/\" + base64_string))"
      ],
      "metadata": {
        "id": "mE2hcw8jugIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create an `.env` File\n",
        "\n",
        "Next you'll create a `.env` file to store your API keys.\n",
        "In the file browser on the left, create a new file and name it `.env`.\n",
        "\n",
        "**Note**: It may disappear as soon as you create it. This is because Google Collab hides hidden files (files that start with a `.`) by default.\n",
        "To make this file appear, click the icon that is a crossed out eye and hidden files will appear.\n",
        "\n",
        "Then double click on the `.env` file and add the following line with your API key.\n",
        "\n",
        "```\n",
        "LLM_API_KEY = YOUR_API_KEY\n",
        "LLM_MODEL = \"openai/gpt-4o\"\n",
        "```\n",
        "\n",
        "By default this notebook uses OpenAI's GPT-4o.\n",
        "If you want to use a different LLM provider, look up the appropriate model name [in their documentation](https://docs.litellm.ai/docs/providers) and change the `LLM_MODEL` field and provide your API key."
      ],
      "metadata": {
        "id": "HXp3VIAdZuhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create .env file\n",
        "with open(\".env\", \"w\") as fh:\n",
        "  fh.write(\"LLM_API_KEY = YOUR_API_KEY\\nLLM_MODEL = openai/gpt-4o\")\n",
        "\n",
        "# Now open the file and replace YOUR_API_KEY with your API key."
      ],
      "metadata": {
        "id": "tSl-K8ATXLJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load environment variables and configure LLM settings\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(override=True)\n",
        "\n",
        "# Get LLM_API_KEY environment variable and print it to make sure that your .env file is properly loaded.\n",
        "LLM_MODEL = os.getenv(\"LLM_MODEL\", \"openai/gpt-4o\")\n",
        "LLM_API_KEY = os.getenv(\"LLM_API_KEY\", None)\n",
        "print(\"LLM API Key\", LLM_API_KEY)"
      ],
      "metadata": {
        "id": "fy4s0KTRdWxL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeb4f95c-1849-46f0-a4fb-cc015cf2f086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM API Key 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\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting the Scnee\n",
        "\n",
        "While a human agent can handle 2.6 tickets per hour; however, the average business has 578 tickets per day.\n",
        "\n",
        "Now imagine, you have 10,000 customer support tickets, three time zones, and customers who want answers now. How do you solve this without hiring 100 people? That's where AI agents come in."
      ],
      "metadata": {
        "id": "OaRTC96z0Hxu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is an AI Agent?\n",
        "\n",
        "An autonomous system that pursues goals through continuous decision-making and action\n",
        "\n",
        "Think of an AI agent as an autonomous system that doesn't just respond once, but continuously works toward achieving a specific goal. Unlike traditional software that follows predetermined steps, an AI agent makes decisions dynamically based on the current situation and available information.\n",
        "\n",
        "An example is a customer support AI agent. The agent doesn't just execute a single function - it pursues the goal of \"resolving dispute and retain customer\" through ongoing decision-making until the situation is fully handled."
      ],
      "metadata": {
        "id": "18qFIGPokZO7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompting the LLM\n",
        "\n",
        "Our agent will use LLM calls to process information and decide what actions to take.\n",
        "\n",
        "We use `litellm` here, which is a unified interface for over 100+ LLM providers. This means that the same code works with different models - you only need to change the model string. All you need to do is provide an API key."
      ],
      "metadata": {
        "id": "iKQTomi_ODQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from litellm import completion, ModelResponse\n",
        "\n",
        "def llm_call(prompt: str, llm_api_key: str, llm_model: str) -> ModelResponse:\n",
        "    response = completion(\n",
        "      model=llm_model,\n",
        "      api_key=llm_api_key,\n",
        "      messages=[{ \"content\": prompt,\"role\": \"user\"}]\n",
        "    )\n",
        "    return response\n",
        "\n",
        "# Change this to a fun prompt of your choice!\n",
        "prompt = \"Give me 5 fun Tardigrade facts in the form of a sea shanty.\"\n",
        "\n",
        "result = llm_call(prompt, LLM_API_KEY, LLM_MODEL)[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "3yhd-464Imwb",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fb0646e-a904-4ab2-f1c5-70b77b752580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Verse 1)  \n",
            "Oh, the mighty tardigrade sails through streams,  \n",
            "A tiny sailor in our wildest dreams.  \n",
            "Eight-legged and tougher than the brine,  \n",
            "In ocean's depths or lands divine.  \n",
            "\n",
            "(Chorus)  \n",
            "Hey, ho, the tardigrades go,  \n",
            "Resilient and hearty, through waters they flow.  \n",
            "Sing of the critter who'll never fade,  \n",
            "For none can outlast the brave tardigrade!  \n",
            "\n",
            "(Verse 2)  \n",
            "In freezing ice or scalding heat they thrive,  \n",
            "Mighty survivors, they'll stay alive.  \n",
            "Without a drop of water for years on end,  \n",
            "The tardigrade laughs, “I’ve got time to spend!”  \n",
            "\n",
            "(Chorus)  \n",
            "Hey, ho, the tardigrades go,  \n",
            "Boundless and strong, through worlds unknown.  \n",
            "Sing of the creature that time cannot raid,  \n",
            "The ever-resilient, bold tardigrade!  \n",
            "\n",
            "(Verse 3)  \n",
            "To the far reaches of outer space,  \n",
            "A tardigrade’s heart keeps up the pace.  \n",
            "Radiation burns and cosmic storms,  \n",
            "Yet in the cosmos, they bravely perform.  \n",
            "\n",
            "(Chorus)  \n",
            "Hey, ho, the tardigrades go,  \n",
            "To places where no others dare roam.  \n",
            "Sing of the marvels in stardust arrayed,  \n",
            "That wondrous and wise old tardigrade!  \n",
            "\n",
            "(Verse 4)  \n",
            "Shrunken tight in a tun they lay,  \n",
            "Awaiting the sunshine of a brand new day.  \n",
            "Rehydration brings them back to life,  \n",
            "Reclaiming the lands without any strife.  \n",
            "\n",
            "(Chorus)  \n",
            "Hey, ho, the tardigrades go,  \n",
            "Resting in peace till the warm winds blow.  \n",
            "Sing of the lurker 'neath moss and glade,  \n",
            "That miracle beast, the sweet tardigrade!  \n",
            "\n",
            "(Verse 5)  \n",
            "Oh, the tiniest creatures can oft surprise,  \n",
            "With endurance and spirit beyond their size.  \n",
            "Let us raise a glass to these beasts so grand,  \n",
            "The tardigrades of sea and land!  \n",
            "\n",
            "(Chorus)  \n",
            "Hey, ho, the tardigrades go,  \n",
            "Legends of life, both high and low.  \n",
            "Sing of the beast that will never degrade,  \n",
            "All hail to the mighty, brave tardigrade!  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompting the User\n",
        "\n",
        "Now that we have our LLM call, we can write the code to prompt the user for their research topic.\n",
        "\n",
        "1. We can write the code to prompt the user for their research topic.\n",
        "2. Their input becomes the prompt sent directly to the LLM.\n",
        "3. The LLM processes the request and returns a research response\n",
        "4. We display the results back to the user"
      ],
      "metadata": {
        "id": "kQhhd2TcPbyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the API call\n",
        "print(\"Welcome to the Research Report Generator!\")\n",
        "prompt = input(\"Enter your research topic or question: \")\n",
        "result = llm_call(prompt, LLM_API_KEY, LLM_MODEL)\n",
        "\n",
        "# Extract the response content\n",
        "response_content = result[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "print(\"Research complete!\")\n",
        "print(\"-\"*80)\n",
        "print(response_content)\n"
      ],
      "metadata": {
        "id": "dO4qfPdSOCyI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5286ff17-fcbc-4744-bccd-8e720af4c7cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Research Report Generator!\n",
            "Enter your research topic or question: Pikachus\n",
            "Research complete!\n",
            "--------------------------------------------------------------------------------\n",
            "Pikachu is one of the most iconic characters from the Pokémon franchise, created by Nintendo, Game Freak, and Creatures. It is an Electric-type Pokémon and is known for its bright yellow fur and elongated ears tipped with black. Pikachu's signature ability is generating electricity, which it releases through its red cheek pouches. This character is often associated with the Pokémon mascot, thanks to its central role in the Pokémon TV series, games, and merchandise.\n",
            "\n",
            "Pikachu evolves from Pichu when leveled up with high friendship and can further evolve into Raichu when exposed to a Thunder Stone. Pikachu is well-loved worldwide and has become a symbol of the broader Pokémon phenomenon. If you have specific questions about Pikachu or want more details about its role in different Pokémon media or games, feel free to ask!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is a Tool?\n",
        "\n",
        "A tool is an external function that AI systems can call to perform specific tasks beyond just generating text. They take real actions.\n",
        "\n",
        "Examples:\n",
        "- Information retrieval (web search, database query, file reading)\n",
        "- Communication tools (sending emails, post to Slack, sending text messages or notifications)\n",
        "- Data analysis tools (run calculations, generate charts and graphs)\n",
        "- Creative tools (image generation, document creation)\n"
      ],
      "metadata": {
        "id": "q7pd_Qnwa4BF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diagram = \"\"\"\n",
        "graph LR\n",
        "    Goal[the goal] --> LLM[LLM<br/>makes decisions on<br/>what to do next]\n",
        "    LLM --> Tool[Tool<br/>does what the LLM<br/>decided]\n",
        "    Tool --> LLM\n",
        "\"\"\"\n",
        "render_mermaid(diagram)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "wHglPO_L7XNB",
        "outputId": "2ef1d05a-3e4d-4373-8161-47451aedd201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://mermaid.ink/img/CmdyYXBoIExSCiAgICBHb2FsW3RoZSBnb2FsXSAtLT4gTExNW0xMTTxici8+bWFrZXMgZGVjaXNpb25zIG9uPGJyLz53aGF0IHRvIGRvIG5leHRdCiAgICBMTE0gLS0+IFRvb2xbVG9vbDxici8+ZG9lcyB3aGF0IHRoZSBMTE08YnIvPmRlY2lkZWRdCiAgICBUb29sIC0tPiBMTE0K\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So putting this information together, the agent is generally implemented as an event loop that is kicked off with an expression of some goal.\n",
        "In the loop, it:\n",
        "- Asks the LLM to determine the next steps in the flow, and then\n",
        "- Invokes one or more tools to perform those actions.\n",
        "- It keeps looping until the LLM hits its goal or the user stops it."
      ],
      "metadata": {
        "id": "n-OCCZGZ71E_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diagram = \"\"\"\n",
        "graph LR\n",
        "    Bootstrap[bootstrap the agentic loop] --> LLM[LLM<br/>makes decisions on<br/>what to do next]\n",
        "    LLM --> |prepare for tool execution| Tool[Tool<br/>does what the LLM<br/>decided]\n",
        "    Tool --> |update the input to the LLM<br/>for the next turn| LLM\n",
        "\n",
        "    UX[UX i.e. tool<br/>confirmation] -.-> Tool\n",
        "    Library[Tool Library] -.-> Tool\n",
        "\n",
        "    style UX fill:#f9f9f9\n",
        "    style Library fill:#f9f9f9\n",
        "\"\"\"\n",
        "render_mermaid(diagram)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "_a4pWRdE8BTy",
        "outputId": "2a601f04-5418-40e9-d4e5-bc9bbca07537"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://mermaid.ink/img/CmdyYXBoIExSCiAgICBCb290c3RyYXBbYm9vdHN0cmFwIHRoZSBhZ2VudGljIGxvb3BdIC0tPiBMTE1bTExNPGJyLz5tYWtlcyBkZWNpc2lvbnMgb248YnIvPndoYXQgdG8gZG8gbmV4dF0KICAgIExMTSAtLT4gfHByZXBhcmUgZm9yIHRvb2wgZXhlY3V0aW9ufCBUb29sW1Rvb2w8YnIvPmRvZXMgd2hhdCB0aGUgTExNPGJyLz5kZWNpZGVkXQogICAgVG9vbCAtLT4gfHVwZGF0ZSB0aGUgaW5wdXQgdG8gdGhlIExMTTxici8+Zm9yIHRoZSBuZXh0IHR1cm58IExMTQogICAgCiAgICBVWFtVWCBpLmUuIHRvb2w8YnIvPmNvbmZpcm1hdGlvbl0gLS4tPiBUb29sCiAgICBMaWJyYXJ5W1Rvb2wgTGlicmFyeV0gLS4tPiBUb29sCiAgICAKICAgIHN0eWxlIFVYIGZpbGw6I2Y5ZjlmOQogICAgc3R5bGUgTGlicmFyeSBmaWxsOiNmOWY5ZjkK\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- An agent has a fixed set of tools available to it\n",
        "- Each time the LLM responds with some instruction, it is the job of the agent to take that response and make preparations for tool execution. The agent may ask the user for confirmation before executing the tool. And after a tool is executed, it is the job of the agent to update the content that is fed to the LLM for the next turn."
      ],
      "metadata": {
        "id": "luYwKjiA8Fh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating a PDF\n",
        "\n",
        "Agents become powerful when they can perform actions beyond just generating text, and that is what a tool does.\n",
        "\n",
        "Once you have your research data, you’ll write it out to a PDF. We’ll use this later as a tool for our Agent to call.\n",
        "\n",
        "Remember, tools are functions the agent can call to interact with the outside world:\n",
        "- File operations (like this PDF generator)\n",
        "- API calls to external services\n",
        "- Database queries\n",
        "- Email sending\n",
        "- Web scraping\n"
      ],
      "metadata": {
        "id": "xFDnI_5GKZVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Wfrom reportlab.lib.pagesizes import letter\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
        "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
        "from reportlab.lib.units import inch\n",
        "\n",
        "def create_pdf(content: str, filename: str = \"research_report.pdf\") -> str:\n",
        "    doc = SimpleDocTemplate(filename, pagesize=letter)\n",
        "\n",
        "    styles = getSampleStyleSheet()\n",
        "    title_style = ParagraphStyle(\n",
        "        'CustomTitle',\n",
        "        parent=styles['Heading1'],\n",
        "        fontSize=24,\n",
        "        spaceAfter=30,\n",
        "        alignment=1\n",
        "    )\n",
        "\n",
        "    story = []\n",
        "    title = Paragraph(\"Research Report\", title_style)\n",
        "    story.append(title)\n",
        "    story.append(Spacer(1, 20))\n",
        "\n",
        "    paragraphs = content.split('\\n\\n')\n",
        "    for para in paragraphs:\n",
        "        if para.strip():\n",
        "            p = Paragraph(para.strip(), styles['Normal'])\n",
        "            story.append(p)\n",
        "            story.append(Spacer(1, 12))\n",
        "\n",
        "    doc.build(story)\n",
        "    return filename\n",
        "\n",
        "create_pdf(\"Hello PDF!\", filename=\"test.pdf\")"
      ],
      "metadata": {
        "id": "mcZJej_5Y8Nm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a4162da9-f989-43fb-e5f5-5d82b045688d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'test.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Open the PDF\n",
        "\n",
        "Download the `test.pdf` PDF and open it. You should see a title **Research Report** and the words **Hello PDF!** in the document.\n",
        "\n",
        "We'll next combine this with what we've seen already - we'll use our agent to respond to your prompt, then call the `create_pdf` tool to create a PDF with the response to your prompt!\n",
        "\n",
        "See how neat this is? Instead of just printing text to the console, your agent now creates a tangible deliverable. You ask a question, get a response, and walk away with a professional PDF report."
      ],
      "metadata": {
        "id": "Lf1eZE8LeRB5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bringing it all Together\n",
        "\n",
        "You now have multiple functions that you can execute to achieve a task.\n",
        "Next, write the code to bring this all together."
      ],
      "metadata": {
        "id": "alyrd1xbiC4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the API call\n",
        "print(\"Welcome to the Research Report Generator!\")\n",
        "prompt = input(\"Enter your research topic or question: \")\n",
        "result = llm_call(prompt, LLM_API_KEY, LLM_MODEL)\n",
        "\n",
        "# Extract the response content\n",
        "response_content: str = result[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "pdf_filename = create_pdf(response_content, \"research_report.pdf\")\n",
        "print(f\"SUCCESS! PDF created: {pdf_filename}\")\n"
      ],
      "metadata": {
        "id": "-9dmy84DiQOD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65b5debf-73bf-473c-87fc-52b13cb8a7ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Research Report Generator!\n",
            "Enter your research topic or question: Give me 2 facts about pikachus\n",
            "SUCCESS! PDF created: research_report.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Foundations of an Agentic Application\n",
        "\n",
        "You now have the foundations of an Agentic AI application.\n",
        "\n",
        "What makes this agentic?\n",
        "1. It's goal-oriented: it has a clear objective (generate a research report)\n",
        "2. Tool usage: it combines multiple capabilities (LLM reasoning + PDF generation)\n",
        "3. Autonomous decision making: the LLM decides how to structure and present the research\n",
        "\n",
        "The functions you created are your \"tools\": `llm_call` and `create_pdf`. Some may think that an Agentic AI must have a loop, but that's not the case."
      ],
      "metadata": {
        "id": "t3GhdUXmiycf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agentic Challenges\n",
        "\n",
        "However, there are a few significant challenges to getting production AI at scale.\n",
        "\n",
        "Your simple agent works great in demos, but production environments are messy and unpredictable.\n",
        "\n",
        "- Tool resources (APIs and databases) go down\n",
        "- Rate limiting on the LLM might cause it to fail, even if only intermittently\n",
        "- LLMs are inherently non-deterministic\n",
        "- Networks can go down.\n",
        "\n",
        "Imagine if the user asks for report → LLM times out → half-generated PDF → frustrated user. Let's explore a bit more.\n"
      ],
      "metadata": {
        "id": "0gnTPrw3yNcD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Event Loop\n",
        "\n",
        "At a high level, AI agents are pretty simple. We have an event loop, and in that event loop, we make calls out to the LLM to ask it for directions. It’s what is driving the flow of the application.\n",
        "\n",
        "At that direction, we might invoke some downstream tools (e.g.: make some microservice requests).\n",
        "\n",
        "Then we consult with the user, and then go through the loop again."
      ],
      "metadata": {
        "id": "2fIVUmIu6KJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diagram = \"\"\"\n",
        "graph LR\n",
        "    P[Plan/Next Step] --> E[Execute]\n",
        "    E --> O[Observe]\n",
        "    O --> P\n",
        "\"\"\"\n",
        "render_mermaid(diagram)"
      ],
      "metadata": {
        "id": "CLY0zS6DvjIQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "766b8ed5-77f5-4d76-9995-4a553b6eac34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://mermaid.ink/img/CmdyYXBoIExSCiAgICBQW1BsYW4vTmV4dCBTdGVwXSAtLT4gRVtFeGVjdXRlXQogICAgRSAtLT4gT1tPYnNlcnZlXQogICAgTyAtLT4gUAo=\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agents Don't Work in Isolation\n",
        "\n",
        "* When we invoke the tools, we are making downstream service requests, like to a microservice. However, increasingly those downstream service requests are going to additional agents.\n",
        "Each of these nodes has its own event loop: plan/next step -> execute -> observe (see diagram below)\n",
        "* They can call other agents which call other agents, creating complex networks. Each agent has its own logic and potential failure points.\n",
        "  * Example: Research Agent → Web Search Agent + Data Analysis Agent → Report Generator Agent"
      ],
      "metadata": {
        "id": "_26Y2tjERPHq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agents Call Other Agents\n",
        "\n",
        "Increasingly, we are seeing agents calling agents, which are calling other agents. Your research agent might ask: \"Write a report on renewable energy trends.\"\n",
        "  * Call a \"Web Scraper\" agent to gather sources (scrapes 5 energy websites)\n",
        "  * Call a \"Fact Checker\" agent to verify claims (validates statistics about government data)\n",
        "  * Call a \"Citation\" agent to format references (formats 12 sources in APA style)\n",
        "  * Call a \"PDF Generator\" agent (what you built! Creates a final 8-page report)\n",
        "\n",
        "This means your \"simple\" research request triggers a complex orchestration. If any agent fails at step 2 or 3, you lose all the work from previous steps and have to start over. This can get expensive!\n",
        "\n",
        "Now over lay what can go wrong: network partitions, timeouts, and service failures at any step can break the chain anywhere!"
      ],
      "metadata": {
        "id": "S-cD7kk0rTqL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Your Agent in Production\n",
        "\n",
        "  What you built:\n",
        "  - 1 LLM call\n",
        "  - 1 PDF generation\n",
        "\n",
        "  In production, this becomes:\n",
        "  - Multiple LLM calls across different agents\n",
        "  - External API calls (web scraping, databases)\n",
        "  - File system operations\n",
        "  - Network failures at any step\n",
        "  - Need to coordinate responses from multiple agents\n",
        "\n",
        "The bottom line: What looks like one AI task is actually a distributed system challenge!"
      ],
      "metadata": {
        "id": "aIkENgxorl8I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agents are Distributed Systems\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src='https://drive.google.com/uc?id=1yynE1_HDDVuFQjaesFcxyds045MzTkfo' />\n",
        "<figcaption>The Truth About AI Agents</figcaption></center>\n",
        "</figure>"
      ],
      "metadata": {
        "id": "4hcPLb8GWhpc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This is Why Agents == Workflows\n",
        "\n",
        "  Your research agent needs to:\n",
        "  1. Accept user input\n",
        "    - Possible problems: input validation service, rate limiting\n",
        "  2. Call the LLM for research\n",
        "    - Possible problems: Internet connection, API down, rate limiting, timeout\n",
        "  3. Generate PDF\n",
        "    - Possible problems: Memory limits\n",
        "  4. Return success/failure\n",
        "    - Possible problem: Connection dropped\n",
        "\n",
        "  Each step can fail.\n",
        "  Each step might need different agents.\n",
        "  This is a **workflow** - and workflows need orchestration."
      ],
      "metadata": {
        "id": "Fl6jmr_tvG86"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Putting It Together\n",
        "\n",
        "To create a reliable agent, we need:\n",
        "\n",
        "1. Durable Event Loop - An application that provides a durable implementation of the event loop—one capable of recovering from crashes and resuming exactly where it left off in the event of a failure.\n",
        "\n",
        "2. Durable Invocation System - A system for durable invocation of LLMs and tools, ensuring that requests persist through transient issues such as network disruptions, service outages, or rate limits, and complete successfully once conditions allow."
      ],
      "metadata": {
        "id": "dJ9n-9ne8Iol"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Exercise 1 - Adding More Tools\n",
        "\n",
        "* In this exercise, you'll:\n",
        "  * Call tools with your agent\n",
        "  * Extract structured information from LLM responses to coordinate between different tools.\n",
        "* Go to the **Exercise** Directory in the Google Drive and open the **Practice** Directory\n",
        "* Open _01-An-AI-Agent-Practice.ipynb_ and follow the instructions and filling in the `TODO` statements.\n",
        "* If you get stuck, raise your hand and someone will come by and help. You can also check the `Solution` directory for the answers\n",
        "* **You have 5 mins**"
      ],
      "metadata": {
        "id": "Pbw85OliybvN"
      }
    }
  ]
}